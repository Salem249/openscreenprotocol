<pre class='metadata'>
Title: Open Screen Protocol
Shortname: openscreenprotocol
Level: 1
Status: w3c/ED
ED: https://webscreens.github.io/openscreenprotocol/
Canonical URL: ED
Editor: Mark Foltz, Google, https://github.com/mfoltzgoogle, w3cid 68454
Repository: webscreens/openscreenprotocol
Abstract: The Open Screen Protocol is a suite of network protocols that allow user agents to implement the [[PRESENTATION-API|Presentation API]] and the [[REMOTE-PLAYBACK|Remote Playback API]] in an interoperable fashion.
Group: Second Screen Community Group
Mailing List: public-webscreens@w3c.org
Mailing List Archives: https://lists.w3.org/Archives/Public/public-webscreens/
Markup Shorthands: markdown yes, dfn yes, idl yes
</pre>

<p boilerplate="copyright">
<a href="http://www.w3.org/Consortium/Legal/ipr-notice#Copyright">Copyright</a> Â© [YEAR] the Contributors to the [TITLE] Specification, published by the <a href="https://www.w3.org/community/webscreens/">Second Screen Community Group</a> under the <a href="https://www.w3.org/community/about/agreements/cla/">W3C Community Contributor License Agreement (CLA)</a>.
A human-readable <a href="http://www.w3.org/community/about/agreements/cla-deed/">summary</a> is available.
</p>

<!-- TODO: Add short names to Presentation API spec, so that BS autolinking works as designed. -->
<!-- TODO: Can autolinks to HTML51 be automatically generated? -->
<pre class="anchors">
urlPrefix: https://w3c.github.io/presentation-api/#dfn-; type: dfn; spec: PRESENTATION-API
    text: controller
    text: controlling user agent
    text: controlling browsing context
    text: presentation
    text: presentation display
    text: presentation display availability
    text: presentation id
    text: presentation request url
    text: receiver
    text: receiving browsing context
    text: receiving user agent
urlPrefix: https://w3c.github.io/presentation-api/; type: interface; spec: PRESENTATION-API
    text: PresentationConnection
urlPrefix: https://w3c.github.io/remote-playback/#dfn-; type: dfn; spec: REMOTE-PLAYBACK
    text: remote playback device
urlPrefix: https://www.w3.org/TR/html51/single-page.html; type: dfn; spec: HTML51
    text: media element
</pre>

<h2 class='no-num no-toc no-ref' id='status'>Status of this document</h2>

This specification was published by the [Second Screen Community
Group](https://www.w3.org/community/webscreens/). It is not a W3C Standard nor
is it on the W3C Standards Track. It should not be viewed as a stable
specification, and may change in substantial ways at any time. A future version
of this document will be published as a Community Group Report.

Please note that under the [W3C Community Contributor License Agreement
(CLA)](https://www.w3.org/community/about/agreements/cla/) there is a limited
opt-out and other conditions apply.

Learn more about [W3C Community and Business
Groups](http://www.w3.org/community/).

Introduction {#introduction}
============================

The Open Screen Protocol connects browsers to devices capable of rendering Web
content for a shared audience.  Typically, these are devices like
Internet-connected TVs, HDMI dongles, or "smart" speakers.

The protocol is suite of subsidiary network protocols that enable two user
agents to implement the [[PRESENTATION-API|Presentation API]] and
[[REMOTE-PLAYBACK|Remote Playback API]] in an interoperable fashion.  This means
that a user can expect these APIs work as intended when connecting two devices
from independent implementations of the Open Screen Protocol.

The Open Screen Protocol is a specific implementation of these two APIs, meaning
that it does not handle all possible ways that browsers and presentation
displays could support these APIs.  The Open Screen Protocol specifically
supports browsers and displays that are connected via the same local area
network, and that initiate presentation or remote playback by sending a URL
from the browser to the target display.

The Open Screen Protocol is intended to be extensible, so that additional
capabilities can be added over time.  This may include new implementations of
existing APIs, or new APIs.

Terminology {#terminology}
--------------------------

We borrow terminology from the [[PRESENTATION-API|Presentation API]] and
[[REMOTE-PLAYBACK|Remote Playback API]] for terms used in this document.  These
terms are summarized here.

We call the browser that is used to discover and initiate presentation of Web
content on another device the [=controlling user agent=].  We call the
user agent on the device rendering the Web content the
[=receiving user agent=], or *receiver* for short.  We use
the term [=presentation display=] to refer to the entire platform and
responsible for implementing the *receiver*, including browser, OS, networking,
audio and graphics.

For the [[PRESENTATION-API|Presentation API]], presentation of Web content is
initiated at the request of a [=controlling browsing context=] (or
*controller*), which creates a [=receiving browsing context=] (or
*presentation*) to load a [=presentation request URL=] and exchange messages
with the resulting document.

Before this can happen, the [=controlling user agent=] must determine which
[=receivers=], if any, are compatible with the [=presentation request URL=].  This
happens by determining the [=presentation display availability=] for the
presentation request URL.

For the [[REMOTE-PLAYBACK|Remote Playback API]], the device responsible for
rendering the content of a [=media element=] when remote playback is connected
is called the [=remote playback device=].

For additional terms and idioms specific to the [[PRESENTATION-API|Presentation API]] or
Remote Playback API, please consult the respective specifications.

Requirements {#requirements}
============================

Presentation API Requirements {#requirements-presentation-api}
--------------------------------------------------------------

1.  A controlling user agent must be able to discover the presence of a
    presentation display connected to the same IPv4 or IPv6 subnet and reachable
    by IP multicast.

2.  A controlling user agent must be able to obtain the IPv4 or IPv6 address of
    the display, a friendly name for the display, and an IP port number for
    establishing a network transport to the display.

3.  A controlling user agent must be able to determine if the receiver is
    reasonably capable of rendering a specific [=presentation request URL=].

4.  A controlling user agent must be able to start a new presentation on a receiver given a
    [=presentation request URL=] and [=presentation ID=].

5.  A controlling user agent must be able to create a new
    {{PresentationConnection}} to an existing presentation on the
    receiver, given its [=presentation request URL=] and [=presentation ID=].

6.  It must be possible to to close a {{PresentationConnection}} between a
    controller and a presentation, and signal both parties with the
    reason why the connection was closed.

7.  Multiple controllers must be able to connect to a single presentation
    simultaneously, possibly from from one or more [=controlling user agents=].

8.  Messages sent by the controller must be delivered to the presentation (or
    vice versa) in a reliable and in-order fashion.

9.  If a message cannot be delivered, then the controlling user agent must be
    able to signal the receiver (or vice versa) that the connection should be
    closed with reason `error`.

10. The controller and presentation must be able to send and receive `DOMString`
    messages (represented as `string` type in ECMAScript).

11. The controller and presentation must be able to send and receive binary
    messages (represented as `Blob` objects in HTML5, or `ArrayBuffer` or
    `ArrayBufferView` types in ECMAScript).

12. The controlling user agent must be able to signal to the receiver to
    terminate a presentation, given its [=presentation request URL=] and [=presentation
    ID=].

13. The receiver must be able to signal all connected controlling user agents
    when a presentation is terminated.


Remote Playback API Requirements {#requirements-remote-playback}
----------------------------------------------------------------

Issue(3): Requirements for Remote Playback API

Non-Functional Requirements {#requirements-non-functional}
----------------------------------------------------------

1.  It should be possible to implement an Open Screen presentation display using
    modest hardware requirements, similar to what is found in a low end
    smartphone, smart TV or streaming device. See the [Device
    Specifications](device_specs.md) document for expected presentation display
    hardware specifications.

2.  It should be possible to implement an Open Screen controlling user agent on a
    low-end smartphone. See the [Device Specifications](device_specs.md) document
    for expected controlling user agent hardware specifications.
 
3.  The discovery and connection protocols should minimize power consumption,
    especially on the controlling user agent which is likely to be battery
    powered.
 
4.  The protocol should minimize the amount of information provided to a passive
    network observer about the identity of the user, activity on the controlling
    user agent and activity on the receiver.
 
5.  The protocol should prevent passive network eavesdroppers from learning
    presentation URLs, presentation IDs, or the content of presentation messages
    passed between controllers and presentations.
 
6.  The protocol should prevent active network attackers from impersonating a
    display and observing or altering data intended for the controller or
    presentation.
 
7.  The controlling user agent should be able to discover quickly when a
    presentation display becomes available or unavailable (i.e., when it connects
    or disconnects from the network).
 
8.  The controlling user agent should present sensible information to the user
    when a protocol operation fails.  For example, if a controlling user agent is
    unable to start a presentation, it should be possible to report in the
    controlling user agent interface if it was a network error, authentication
    error, or the presentation content failed to load.
 
9.  The controlling user agent should be able to remember authenticated
    presentation displays.  This means it is not required for the user to
    intervene and re-authenticate each time the controlling user agent connects
    to a pre-authenticated display.
 
10.  Message latency between the controller and a presentation should be minimized
    to permit interactive use.  For example, it should be comfortable to type in
    a form in the controller and have the text appear in the presentation in real
    time.  Real-time latency for gaming or mouse use is ideal, but not a
    requirement.
 
11. The controlling user agent initiating a presentation should communicate its
    preferred locale to the receiver, so it can render the presentation content
    in that locale.
 
12. It should be possible to extend the control protocol (above the discovery and
    transport levels) with optional features not defined explicitly by the
    specification, to facilitate experimentation and enhancement of the base
    APIs.
 

Discovery with mDNS {#discovery}
===============================

Endpoints may discover one another using
[mDNS](https://tools.ietf.org/html/rfc6762) and
[DNS-SD](https://tools.ietf.org/html/rfc6763).  To do so, endpoints must use the
service name "_openscreen._udp.local".

Endpoints must include DNS TXT records with the following keys and values: 

- key "fp" with value of the certificate fingerpint of the endpoint.  The format
  of the fingerprint is defined by [RFC 8122 section
  5](https://tools.ietf.org/html/rfc8122#section-5), excluding the
  "fingerprint:" prefix and including the hash function, space, and hex-encoded
  fingerprint.  The fingerprint value also functions as an ID for the endpoint.
  All endpoints must support the following hash functions: "sha-256", "sha-512".
  Endpoints must not support the following hash functions: "md2", "md5". 

- key "time" with value of the last time the endpoint updated its
  metadata.  The time value is represented as zero or a positive integer.  The
  clock and timescale are chosen by the advertising endpoint, but are not
  important, except that the clock must be monotonic.  A larger value is an
  indication to discovering clients that they should reconnect to the
  advertising client to learn updated metadata.  
 
An endpoint that publishes this service name must implement the
transport and metadata discovery mechanism with QUIC described below.
If a future version of this protocol uses mDNS but breaks
compatibility with that mechanism, it should change the service name
to a new value indicating a new mechanism for metadata discovery
mechanism.  If future versions of this protocol or extensions to this
protocol are compatible with the metadata discovery mechanism, they
can use it to indicate support for future versions and extensions.


Transport and metadata discovery with QUIC {#transport}
=======================================================

If a discovering endpoint wants to connect to an advertising endpoint, or to
learn further metdata about it, it initiates a
[QUIC](https://tools.ietf.org/html/draft-ietf-quic-transport-16) connection to
the IP and port from the SRV record.  Prior to authentication, some message may be
exchanged (such as further metadata), but such info should be treated as
unauthenticated (such as indicating to a user that a display name of an
unauthenticated endpoint is unauthenticated).  

To learn further metadata, an endpoint may send an endpoint-info-request
message (see Appendix A) and receive back an endpoint-info-response message.  The
messages may contain the following information with the following meaning:

- display-name: The display name of the responding endpoint intended to be
  displayed to a user by the requesting endpoint.  If the responding endpoint is
  not yet authenticated, the requesting endpoint should make UI affordance for
  indicating to the user that the display name is not yet authenticated.  If the
  responding endpoint changes its display name, the requesting endpoint should
  make UI affordance for indicating to the user that the display name has
  changed. 

- model-name: The model name of the device (if it is a device), used mainly for
  debugging purposes, but may be displayed to the user of the requesting
  endpoint.

<!-- TODO: Add device type and/or capabilities -->

If a discovering endpoint (acting as a QUIC client) wishes to receive messages
from an advertising endpoint (acting as a QUIC server) or an advertising
endpoint (acting as a QUIC server) wishes to send message to a discovering
endpoint (acting as a client endpoint), it may wish to keep the QUIC connection
alive.  Once neither side needs to keep the connection alive for the purposes of
sending or receiving messages, the connection should be closed.  In order to
keep a QUIC connection alive, an endpoint may send an endpoint-status-request
message, and any endpoint that receives an endpoint-status-request message
should send an endpoint-status-response message.  Such messages should be sent
every 25 seconds.  If, however, other mechanisms or traffic (such as other
requests and responses) are serving the purpose of keeping the connection alive,
these messages should be delayed or not used at all.  A QUIC connection should
not be closed because of idle timeout unless no such mechanisms or traffic has
been received from the remote side for 35 seconds (allowing for a keep-alive
frequency of 25 seconds and message delivery delay of 10 seconds).

If a client endpoint wishes to send messages to a server endpoint, the client
endpoint can connect to the server endpoint "on demand"; it does not need to
keep the connection alive.

The endpoint-info-response message and endpoint-status-response messages may be
extended to include additional information not defined in this spec.  If done
ad hoc by applications and not in future specs, keys should be chosen to avoid
collision, such as by choosing large integers or long strings.  

Messages delivery using CBOR and QUIC streams {#control}
========================================================

Messages are serialized using [CBOR](https://tools.ietf.org/html/rfc7049).  To
send a group of messages in order, that group of messages must be sent in one
QUIC stream.  Different groups of messages which are ordered within the group
but not across groups must be sent in different QUIC streams.  In order to put
multiple CBOR-serialiezd messages into the the same QUIC stream, the following
is used.

For each message, the sender must write to the QUIC stream the following: 
1. A type key representing the type of the message, encoded as a variable-length
   integer (see Appendix A for type keys) 

2. The message length encoded as a variable-length integer 

3. The messge encoded as CBOR (whose length must match the prefixed length)

Future message type keys may indicate the use of custom message formats that are
not CBOR, or use of CBOR without the length prefix, so receiving endpoints must
disregard messages with type keys that it does not recognize and must not assume
that they are serialized using CBOR nor that they have a length prefix.

Variable-length integers are encoded in the same format as defined by [QUIC
transport section
16](https://tools.ietf.org/html/draft-ietf-quic-transport-16#section-16).

Many messages are requests and responses, so a common format is defined for
those.  A request and a response includes a request ID which is an unsigned
integer chosen by the requester.  Responses must include the request ID of the
request they are associated with.  

Authentication {#authentication}
================================

Issue(102): Incorporate material from the \[J-PAKE](j-pake.md) document.

Presentation API Protocol {#presentation-api}
---------------------------------------------

Issue(55): Incorporate material from the
[Protocol](protocol.md) document.

Remote Playback API Protocol {#remote-playback}
-----------------------------------------------

Issue(12): Propose control protocol for Remote
Playback API.

Security and Privacy {#security}
================================

Issue(13): Describe security architecture.

Data to be secured {#security-data}
-----------------------------------

Threat model {#security-threat}
-------------------------------

Mitigations and defenses {#security-defenses}
---------------------------------------------

Appending A: Messages
=====================
The following messages are defined with [CDDL](https://datatracker.ietf.org/doc/draft-ietf-cbor-cddl/). When integer keys are used, a comment is appended to the line to indicate the name of the field. Each root message (one that can be put into a QUIC stream without being inclosed by another message) has a comment indicating the message type key.

Smaller numbers should be reserved for message that will be sent more frequently or are very small or both and larger numbers should be reserved for messsages that are infrequently sent or large or both because smaller type keys encode on the wire smaller.

<pre>
; type key 10
endpoint-info-request = {
  request
}

; type key 11
endpoint-info-response = {
  response
  1: endpoint-info ; endpoint-info
}

endpoint-info = {
  0: text ; friendly-name
  1: text ; model-name
  ; ...
}

; type key 12
endpoint-status-request = {
  request
  ? 1: status ; status
}

; type key 13
endpoint-status-response = {
  response
  ? 1: status ; status
}

status = {
}

request = (
 0: request-id ; request-id
)

response = (
 0: request-id ; request-id
)

request-id = uint

</pre>



